{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP#03.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khdTjc142Xfh"
      },
      "source": [
        "# Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uYmpxCw2Q_X",
        "outputId": "59dbb701-1e17-4edd-ad54-a9d5079af7ca"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import brown\n",
        "\n",
        "import spacy\n",
        "from spacy.tokens import Doc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "nlp = spacy.load('en')\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')\n",
        "\n",
        "!pip install sklearn-crfsuite\n",
        "\n",
        "import sklearn\n",
        "import sklearn_crfsuite\n",
        "\n",
        "from sklearn_crfsuite import metrics\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "from keras.models import Model\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import scipy.spatial.distance as distance\n",
        "\n",
        "!pip install -q annoy\n",
        "\n",
        "import annoy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n",
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.7/dist-packages (0.3.6)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (1.15.0)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (0.9.7)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (0.8.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cymxH4QhCvDI"
      },
      "source": [
        "words = brown.words()\n",
        "sentences = brown.sents()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P8_MNIgKAtQ"
      },
      "source": [
        "# Assign unique ids to each word\n",
        "\n",
        "For this task all the words should be mapped to unique indices\n",
        "indices start from 1 ( 0 is reserved for padding )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ojxpcbr7C5gE"
      },
      "source": [
        "def Assign_ids(words_list):\n",
        "  words_list = list(dict.fromkeys(words_list))\n",
        "  return {k: v+1 for v, k in enumerate(words_list)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmq5VuxxFnAw"
      },
      "source": [
        "ids = Assign_ids(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1F717De_FtSd",
        "outputId": "a724a9b6-c739-408f-d18a-f81350f18507"
      },
      "source": [
        "key_min = min(ids.keys(), key=(lambda k: ids[k]))\n",
        "ids[key_min]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTdeVyU9JsWa"
      },
      "source": [
        "## Global Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7UvN-ljJwiR"
      },
      "source": [
        "\n",
        "################\n",
        "\n",
        "MAX_INPUT_SIZE=10\n",
        "NUM_WORDS = len(ids)\n",
        "\n",
        "################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9T0EmKzLBEf"
      },
      "source": [
        "# String to IDs function\n",
        "\n",
        "This function is responsible for transforming a sentence(spacy document to be precise) to a pair of lists of IDs. The first list represents the sentence without the last word, the second one represents it without the first word.\n",
        "\n",
        "Before returning the result, padding/trimming should be applied to get uniform shapes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylJoD_Q0GurO"
      },
      "source": [
        "def string_to_model_input(sentence): \n",
        " \n",
        "  X=[]\n",
        "  Y=[]\n",
        "  for token in sentence:\n",
        "    X.append(ids[str(token)])\n",
        "    Y.append(ids[str(token)])\n",
        "\n",
        "  X.pop(len(X)-1)\n",
        "  Y.pop(0)\n",
        "\n",
        "  #padding\n",
        "  X = (X + [0] * MAX_INPUT_SIZE)[:MAX_INPUT_SIZE]\n",
        "  Y = (Y + [0] * MAX_INPUT_SIZE)[:MAX_INPUT_SIZE]\n",
        "\n",
        "  return (X,Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OxBzczLcoIX",
        "outputId": "9f8cede0-6b5f-47f0-fabd-f3ca0c003499"
      },
      "source": [
        "string_to_model_input(sentences[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [2, 3, 4, 5, 6, 7, 8, 9, 10, 11])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4xsrWzVVy8Y"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# Runnig the string_to_model_input function on the sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-x6a2anbIgW"
      },
      "source": [
        "X = [ string_to_model_input(sentence)[0] for sentence in sentences ]\n",
        "Y = [ string_to_model_input(sentence)[1] for sentence in sentences ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmucUcb3tTKv"
      },
      "source": [
        "# Building the model\n",
        "\n",
        "This function is for building the language model. It is an LSTM model with an Embedding layer for dimentionality reduction and embedding the corpus. \n",
        "\n",
        "The result of the prediction will be a matrix with dimention (MAX_INPUT_SIZE, 1, NUM_WORDS)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQ9d_Ow3tS6g"
      },
      "source": [
        "def build_model():\n",
        "\n",
        "  # build network topology\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.layers.Embedding(NUM_WORDS, 10 , input_length=MAX_INPUT_SIZE )) \n",
        "  model.add(keras.layers.LSTM( 150 , return_sequences= True )) \n",
        "  model.add(keras.layers.LSTM( 100 , return_sequences= True, name = 'target')) \n",
        "  model.add(keras.layers.Dense(NUM_WORDS, activation= \"softmax\" ))\n",
        "\n",
        "  model. compile (loss=keras.losses.sparse_categorical_crossentropy, optimizer='Adam', metrics = [ 'accuracy' ])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRUYMOt_jGrO"
      },
      "source": [
        "model = build_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PojjFkTXV_Tl"
      },
      "source": [
        "x= X[99]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "y6_Js5DuZ0zo"
      },
      "source": [
        "model.fit(X,Y, epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia3PbWzZzWHi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cf194ed-3873-477e-df90-e8c48dfbdf82"
      },
      "source": [
        "# GET THE TRAINED MODEL FROM DRIVE\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVsa3_EY6blH"
      },
      "source": [
        "model = keras.models.load_model('/content/gdrive/MyDrive/nlp03.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJcxa_u9Tks-"
      },
      "source": [
        "# function for getting the LSTM cell state:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaCtkfZ4eGMu"
      },
      "source": [
        "def get_cell_state(word_id_vector):\n",
        "  intermediate_layer = Model(inputs=model.input, outputs= model.get_layer('target').output)\n",
        "  return intermediate_layer.predict([word_id_vector])[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ct_eGJ6BND4v"
      },
      "source": [
        "# prediction function\n",
        "\n",
        "After the training, the model will be capable of predicting the next word of a sentence. To achieve that, the index of the largest probability in the last row of the predicted matrix (last word) is taken and mapped to the original list of words.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyNiuZbdYhPD"
      },
      "source": [
        "def predict_next_word(x):\n",
        "  \n",
        "  y = model.predict([x])[0]\n",
        "  try:\n",
        "    next_probs = y[x.index(0)].tolist()\n",
        "  except:\n",
        "    next_probs = y[MAX_INPUT_SIZE -1].tolist()\n",
        "  else:\n",
        "    next_probs = y[MAX_INPUT_SIZE - x.index(0)].tolist()\n",
        "  \n",
        "  max_index = next_probs.index(max(next_probs))\n",
        "  return list(ids.keys())[list(ids.values()).index(max_index +1)]\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GT-tH7dHob9i",
        "outputId": "56deb3cf-6c4d-4f19-fce1-800037ea50f3"
      },
      "source": [
        "x= [1,2,3,4,5,6,7,8,9,0]\n",
        "predict_next_word(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'conducted'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwIjfStzJVdu"
      },
      "source": [
        "# Predict next word\n",
        "\n",
        "In this part an input field is available to enter a list of words in a loop.\n",
        "this sequence will be processed and fed to the model to predict the next word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUK1WLUzZhRw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "731ad675-bef6-4c1a-ee5f-dd0616dfc527"
      },
      "source": [
        "initial_text = ''\n",
        "\n",
        "while True:\n",
        "  word= input()\n",
        "  if len(word) == 0:\n",
        "    break\n",
        "  else:\n",
        "    initial_text = initial_text + ' ' +word \n",
        "\n",
        "initial_text = initial_text[1:]\n",
        "initial_text = nlp(initial_text)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello\n",
            "how\n",
            "are\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T--3u4TAPx-o"
      },
      "source": [
        "\n",
        "def string_to_ids(initial_text):\n",
        "  pred_input = []\n",
        "  for token in initial_text:\n",
        "    pred_input.append(ids[token.text])\n",
        "\n",
        "  return (pred_input + [0]*MAX_INPUT_SIZE)[:MAX_INPUT_SIZE]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaAmtHCcEQ5K"
      },
      "source": [
        " pred_input = string_to_ids(initial_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u01qo3v3ntFw",
        "outputId": "09523f96-0ec2-4544-bf3f-53c860817af0"
      },
      "source": [
        "print(\"sentence: \", initial_text, predict_next_word(pred_input))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence:  hello how are The\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6t_ib4WcrzX"
      },
      "source": [
        "# cosine similarity\n",
        "For this similarity metric the cell state of the LSTM layer is used. Thus in this task,a pair of sentences, will be read, transformed to IDs, fed to the model to get the cell states. the result will be flattened then the similarity is calculated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wv_tBKMkIFd5",
        "outputId": "ed59c26b-cd77-42a8-d29c-53deb3eab47e"
      },
      "source": [
        "while True:\n",
        "  print(\"first sentence\")\n",
        "  first_sentence = input()\n",
        "  if len(first_sentence) == 0:\n",
        "    break\n",
        "  print(\"second sentence\")\n",
        "  second_sentence = input()\n",
        "  sentence_pair=[first_sentence, second_sentence]\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first sentence\n",
            "the cat is fast\n",
            "second sentence\n",
            "the dog is fast\n",
            "first sentence\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyU3BSZRcwqV"
      },
      "source": [
        "X = []\n",
        "for sentence in sentence_pair:\n",
        "  ids_sentense = []\n",
        "  sentence = nlp(sentence)\n",
        "  for token in sentence:\n",
        "    ids_sentense.append(ids[token.text])\n",
        "  ids_sentense = (ids_sentense + [0] * MAX_INPUT_SIZE)[:MAX_INPUT_SIZE]\n",
        "  X.append(ids_sentense)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B40Gx0IGfMJp",
        "outputId": "35f2f387-adbd-4952-b731-7b1c99b42c61"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[31, 15809, 143, 4877, 0, 0, 0, 0, 0, 0],\n",
              " [31, 4149, 143, 4877, 0, 0, 0, 0, 0, 0]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do2InoiPkUOE"
      },
      "source": [
        "sentences_cell_states = []\n",
        "for sentence in X:\n",
        "  sentences_cell_states.append(get_cell_state(sentence))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kzuna4ZqDu4"
      },
      "source": [
        "fx1 = [item for sublist in sentences_cell_states[0] for item in sublist]\n",
        "fx2 = [item for sublist in sentences_cell_states[1] for item in sublist]\n",
        "print(len(fx1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-2lulq4jHY2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "805a5150-2867-44ba-d114-ed82975d436e"
      },
      "source": [
        "d = cosine_similarity([fx1], [fx2])\n",
        "\n",
        "print(sentence_pair[0], ' and ', sentence_pair[1], ' are ', d[0][0]*100, '% similar' )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the cat is fast  and  the dog is fast  are  97.88339734077454 %  similar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0Gd5BfTYguQ"
      },
      "source": [
        "# Mini search engine\n",
        "\n",
        "In this task all the corpus sentences should be transformed to IDs, to get all the cell states and index'em with annoy. (I took the first 200 sentences for speed purposes ).\n",
        "\n",
        "then, an input field is provided in a loop to get the word sequence, and search for the 5 nearest neighbors.\n",
        "\n",
        "An additional test is done at the end with the first sentence of the corpus, and the nearest neighbor is the sentence itself as supposed to be. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWHWTSqAfM97"
      },
      "source": [
        "def sentences_to_ids(corpus):\n",
        "  vectors=[]\n",
        "  \n",
        "  for sentence in corpus:\n",
        "    sentence = Doc(nlp.vocab, words=sentence)\n",
        "    vectors.append(string_to_ids(sentence))\n",
        "  return vectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw5orahZXkrm"
      },
      "source": [
        "# Select the first 200 sentence for speed purposes\n",
        "sentences = sentences[:200]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGXce6ARbllh"
      },
      "source": [
        "sentenses_ids = sentences_to_ids(sentences)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mARZJwtvbpn-"
      },
      "source": [
        "def get_all_cell_states(vectors):\n",
        "  statevectors=[]\n",
        "  for vec in vectors:\n",
        "    state = get_cell_state(vec)\n",
        "    statevectors.append(state)\n",
        "  return statevectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C51sywOGa5v"
      },
      "source": [
        "all_statevectors = get_all_cell_states(sentenses_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7f4JpuTZEgj"
      },
      "source": [
        "all_statevectors = np.array(all_statevectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V72jVe_CaOai",
        "outputId": "dd47c5f0-93b0-4ca3-8419-96a2cd2d2759"
      },
      "source": [
        "all_statevectors.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 10, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3McwSv6FjAgw",
        "outputId": "389dd88c-9486-4990-d3e7-2b654fc4ca66"
      },
      "source": [
        "initial_text = ''\n",
        "\n",
        "while True:\n",
        "  word= input()\n",
        "  if len(word) == 0:\n",
        "    break\n",
        "  else:\n",
        "    initial_text = initial_text + ' ' + word \n",
        "\n",
        "initial_text = initial_text[1:]\n",
        "initial_text = nlp(initial_text)\n",
        "search_ids = string_to_ids(initial_text)\n",
        "search_state = get_cell_state(search_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hell\n",
            "is\n",
            "not\n",
            "that\n",
            "bad\n",
            "\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f12c649e710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgQ2PieTbbOf"
      },
      "source": [
        "annoy_index = annoy.AnnoyIndex(1000, metric='angular')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XBBkR4LdKcq"
      },
      "source": [
        "for i in range(all_statevectors.shape[0]):\n",
        "  flate_vec = [item for sublist in all_statevectors[i] for item in sublist]\n",
        "  annoy_index.add_item(i, flate_vec)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1AQV7KyjQLo",
        "outputId": "07c17d20-bea8-4446-c52d-b306fd6714d7"
      },
      "source": [
        "annoy_index.build(100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzNCDlqqlR04",
        "outputId": "3ee3c241-4ee9-40d9-ea56-02913e5bfd0e"
      },
      "source": [
        "v= [item for sublist in search_state for item in sublist]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f12e0478680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbfrsFUukugf"
      },
      "source": [
        "nns = annoy_index.get_nns_by_vector(v, 5, search_k=-1, include_distances=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pV5VU1k2lm_N",
        "outputId": "3be0b2a8-115f-4583-f8b7-a94b6aa4dae9"
      },
      "source": [
        "for n in nns:\n",
        "  print(sentences[n][:MAX_INPUT_SIZE])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Ask', 'jail', 'deputies']\n",
            "['Wards', 'protected']\n",
            "['Colquitt']\n",
            "['``', 'Must', 'solve', 'problem', \"''\"]\n",
            "['Construction', 'bonds']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh5CTqVJqq4b",
        "outputId": "2abe30dc-ff4e-45b4-fc1c-4505be36261d"
      },
      "source": [
        "test = Doc(nlp.vocab, words=sentences[0])\n",
        "search_ids = string_to_ids(test)\n",
        "search_state = get_cell_state(search_ids)\n",
        "\n",
        "v= [item for sublist in search_state for item in sublist]\n",
        "nns = annoy_index.get_nns_by_vector(v, 5, search_k=-1, include_distances=False)\n",
        "nns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f12fcd14e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 76, 154, 75, 91]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp-7cYuWK6M_",
        "outputId": "18006d16-408c-4819-e9f5-e2707954ff73"
      },
      "source": [
        "for n in nns:\n",
        "  print(sentences[n][:MAX_INPUT_SIZE])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of']\n",
            "['Rep.', 'Mac', 'Barber', 'of', 'Commerce', 'is', 'asking', 'the', 'House', 'in']\n",
            "['Rep.', 'James', 'Cotten', 'of', 'Weatherford', 'insisted', 'that', 'a', 'water', 'development']\n",
            "['A', 'veteran', 'Jackson', 'County', 'legislator', 'will', 'ask', 'the', 'Georgia', 'House']\n",
            "['The', 'former', 'county', 'school', 'superintendent', ',', 'George', 'P.', 'Callan', ',']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}